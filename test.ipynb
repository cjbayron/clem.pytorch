{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from learners import Learner, GEM, AGEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_tasks = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import subprocess\n",
    "\n",
    "mnist_path = \"data/mnist.npz\"\n",
    "\n",
    "# URL from: https://github.com/fchollet/keras/blob/master/keras/datasets/mnist.py\n",
    "if not os.path.exists(mnist_path):\n",
    "    subprocess.call(\"wget https://s3.amazonaws.com/img-datasets/mnist.npz\", shell=True)\n",
    "    !mv mnist.npz data/\n",
    "\n",
    "f = np.load('data/mnist.npz')\n",
    "x_tr = torch.from_numpy(f['x_train'])\n",
    "y_tr = torch.from_numpy(f['y_train']).long()\n",
    "x_te = torch.from_numpy(f['x_test'])\n",
    "y_te = torch.from_numpy(f['y_test']).long()\n",
    "f.close()\n",
    "\n",
    "torch.save((x_tr, y_tr), 'data/mnist_train.pt')\n",
    "torch.save((x_te, y_te), 'data/mnist_test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "x_tr, y_tr = torch.load('data/mnist_train.pt') # 60000 samples\n",
    "x_te, y_te = torch.load('data/mnist_test.pt') # 10000 samples\n",
    "\n",
    "# reshape and normalize data\n",
    "x_tr = x_tr.float().view(x_tr.size(0), -1) / 255.0\n",
    "x_te = x_te.float().view(x_te.size(0), -1) / 255.0\n",
    "y_tr = y_tr.view(-1).long()\n",
    "y_te = y_te.view(-1).long()\n",
    "\n",
    "# shuffle datasets\n",
    "p_tr = torch.randperm(x_tr.size(0))\n",
    "p_te = torch.randperm(x_te.size(0))\n",
    "\n",
    "x_tr, y_tr = x_tr[p_tr], y_tr[p_tr]\n",
    "x_te, y_te = x_te[p_te], y_te[p_te]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_task_size = 10000\n",
    "te_task_size = 2000\n",
    "\n",
    "tasks_tr = []\n",
    "tasks_te = []\n",
    "\n",
    "for t in range(n_tasks):\n",
    "    tasks_tr.append([x_tr[t*tr_task_size:(t+1)*tr_task_size], y_tr[t*tr_task_size:(t+1)*tr_task_size]])\n",
    "    tasks_te.append([x_te[t*te_task_size:(t+1)*te_task_size], y_te[t*te_task_size:(t+1)*te_task_size]])\n",
    "\n",
    "torch.save([tasks_tr, tasks_te], 'data/mnist_splitted.pt')\n",
    "torch.save([[x_tr[:(tr_task_size*n_tasks)], y_tr[:(tr_task_size*n_tasks)]],\n",
    "            [x_te[:(te_task_size*n_tasks)], y_te[:(te_task_size*n_tasks)]]], 'data/mnist_all.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewed Split: For simulating training on unbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# probability for each class in each split\n",
    "# each row correspond to a split. each column correspond to a class (0-9)\n",
    "# a cell tells what percentage of data to get from a class, to include in a split\n",
    "class_probs = [\n",
    "    [0.6, 0.6, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.6, 0.6, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.6, 0.6, 0.1, 0.1, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.6, 0.6, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.6, 0.6],\n",
    "]\n",
    "\n",
    "def skewed_split(X, y, class_probs):\n",
    "    '''\n",
    "    '''\n",
    "    count_dict = Counter(y.numpy())\n",
    "    \n",
    "    idxs = [torch.randperm(count_dict[i]) for i in range(len(count_dict))]\n",
    "    for prob_set in class_probs:\n",
    "        idxs_to_get = []\n",
    "        for i in len(prob_set):\n",
    "            end_idx = int(prob_set[i]*count_dict[i])\n",
    "            idxs_to_get.append(idxs[i][:end_idx])\n",
    "            idxs[i] = idxs[i][end_idx:] # update indices\n",
    "        \n",
    "        idxs_to_get = torch.cat(idxs_to_get)\n",
    "        # implement get from data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, drop_prob, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.relu(self.fc1(x)))\n",
    "        logits = self.fc2(out)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-continual Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continual Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
