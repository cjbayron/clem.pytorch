{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clem.pytorch: *Continual Learning using Episodic Memory in PyTorch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UTBD3CUiV5n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from learners import Learner, GEM, AGEM, ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yog_ta5jiV53"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_tasks = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXA48T_OiV6E"
   },
   "source": [
    "### Download MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-qf4mgOiV6G"
   },
   "outputs": [],
   "source": [
    "# Copyright 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "mnist_path = \"data/mnist.npz\"\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "# URL from: https://github.com/fchollet/keras/blob/master/keras/datasets/mnist.py\n",
    "if not os.path.exists(mnist_path):\n",
    "    subprocess.call(\"wget https://s3.amazonaws.com/img-datasets/mnist.npz\", shell=True)\n",
    "    !mv mnist.npz data/\n",
    "\n",
    "f = np.load('data/mnist.npz')\n",
    "x_tr = torch.from_numpy(f['x_train'])\n",
    "y_tr = torch.from_numpy(f['y_train']).long()\n",
    "x_te = torch.from_numpy(f['x_test'])\n",
    "y_te = torch.from_numpy(f['y_test']).long()\n",
    "f.close()\n",
    "\n",
    "torch.save((x_tr, y_tr), 'data/mnist_train.pt')\n",
    "torch.save((x_te, y_te), 'data/mnist_test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADHRj38diV6R"
   },
   "source": [
    "### Preprocessing and Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49UJFab8iV6S"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "x_tr, y_tr = torch.load('data/mnist_train.pt') # 60000 samples\n",
    "x_te, y_te = torch.load('data/mnist_test.pt') # 10000 samples\n",
    "\n",
    "# reshape and normalize data\n",
    "x_tr = x_tr.float().view(x_tr.size(0), -1) / 255.0\n",
    "x_te = x_te.float().view(x_te.size(0), -1) / 255.0\n",
    "y_tr = y_tr.view(-1).long()\n",
    "y_te = y_te.view(-1).long()\n",
    "\n",
    "# shuffle datasets\n",
    "p_tr = torch.randperm(x_tr.size(0))\n",
    "p_te = torch.randperm(x_te.size(0))\n",
    "\n",
    "x_tr, y_tr = x_tr[p_tr], y_tr[p_tr]\n",
    "x_te, y_te = x_te[p_te], y_te[p_te]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nIFBcUQNiV6b"
   },
   "source": [
    "### Split MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7ZLoHwOiV6c"
   },
   "outputs": [],
   "source": [
    "tr_task_size = 10000\n",
    "te_task_size = 2000\n",
    "\n",
    "tasks_tr = []\n",
    "tasks_te = []\n",
    "\n",
    "for t in range(n_tasks):\n",
    "    tasks_tr.append([x_tr[t*tr_task_size:(t+1)*tr_task_size], y_tr[t*tr_task_size:(t+1)*tr_task_size]])\n",
    "    tasks_te.append([x_te[t*te_task_size:(t+1)*te_task_size], y_te[t*te_task_size:(t+1)*te_task_size]])\n",
    "\n",
    "torch.save([tasks_tr, tasks_te], 'data/mnist_splitted.pt')\n",
    "torch.save([[x_tr[:(tr_task_size*n_tasks)], y_tr[:(tr_task_size*n_tasks)]],\n",
    "            [x_te[:(te_task_size*n_tasks)], y_te[:(te_task_size*n_tasks)]]], 'data/mnist_all.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQR99JwwiV6p"
   },
   "source": [
    "### Skewed Split: For simulating training on unbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUtV9GTCiV6r"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# probability for each class in each split\n",
    "# each row correspond to a split. each column correspond to a class (0-9)\n",
    "# a cell tells what percentage of data to get from a class, to include in a split\n",
    "\n",
    "def skewed_split(X, y, class_probs):\n",
    "    '''\n",
    "    '''\n",
    "    count_dict = Counter(y.numpy()) # count_dict[class] = num_of_data_in_class\n",
    "    indices_per_class = [(y==c).nonzero().squeeze() for c in range(len(count_dict))]\n",
    "    # generate random indices TO INDEX THE ACTUAL INDICES for each class\n",
    "    idxs = [torch.randperm(count_dict[i]) for i in range(len(count_dict))]\n",
    "    for prob_set in class_probs:\n",
    "        idxs_to_get = []\n",
    "        for i in range(len(prob_set)):\n",
    "            end_idx = int(prob_set[i]*count_dict[i])\n",
    "            idxs_to_get.append(indices_per_class[i][idxs[i][:end_idx]])\n",
    "            # update indices, we treat the idxs like a stack where we\n",
    "            # remove indices we have already used\n",
    "            idxs[i] = idxs[i][end_idx:]\n",
    "        \n",
    "        idxs_to_get = torch.cat(idxs_to_get)\n",
    "        yield X[idxs_to_get], y[idxs_to_get]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7G6hzL9x31b"
   },
   "outputs": [],
   "source": [
    "def gen_prob_dist(dom_prob):\n",
    "    ''' Function for generating a skewed probability distribution\n",
    "    for each task. This outputs a 5x10 list matrix where each row\n",
    "    correspond to a task, and each column correspond to a class.\n",
    "    Each value represents the percentage of samples of a class\n",
    "    that will be assigned to a task. Concretely, a value of 0.6 at \n",
    "    (row 3, column 2), index starting at 0, means 60% of MNIST training\n",
    "    data labelled as '2' will be assigned to Task 4.\n",
    "    \n",
    "    Each distribution has 2 dominant classes i.e. classes\n",
    "    with the largest probability, whose probabilities are dictated by\n",
    "    the input variable `dom_prob`. For instance, if dom_prob=0.9, row 1\n",
    "    will have 90% of samples from classes '2' & '3'. The remaining 10%\n",
    "    shall then be distributed equally to other tasks i.e. 2.5% for rows 0,2-4.\n",
    "    Following this way of distribution, the full row 1, in this example\n",
    "    shall be: [0.025, 0.025, 0.9, 0.9, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025]\n",
    "    '''\n",
    "    min_prob =  (1.0 - dom_prob) / 4.0\n",
    "    prob_dist = [[min_prob] * 10 for t in range(n_tasks)]\n",
    "    for t in range(n_tasks):\n",
    "        prob_dist[t][t*2] = dom_prob\n",
    "        prob_dist[t][(t*2)+1] = dom_prob\n",
    "      \n",
    "    return prob_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1586079999386,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "zXfCusCC3nPn",
    "outputId": "8e12a983-dbbb-40b1-a64a-4768f832d404"
   },
   "outputs": [],
   "source": [
    "# check generated probabilities\n",
    "sample_probs = gen_prob_dist(0.6)\n",
    "for task_probs in sample_probs:\n",
    "    print(task_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1417,
     "status": "ok",
     "timestamp": 1586080003915,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "VUKLz6FKmzGD",
    "outputId": "469d7384-11ea-4098-eb54-219dcde34e52"
   },
   "outputs": [],
   "source": [
    "# check generated splits\n",
    "for new_x, new_y in skewed_split(x_te, y_te, sample_probs):\n",
    "    print(dict(Counter(new_y.numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0xergpziV6z"
   },
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1uExu8hiV6z"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, drop_prob, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.relu(self.fc1(x)))\n",
    "        logits = self.fc2(out)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6oefEO7iV66"
   },
   "outputs": [],
   "source": [
    "# MNIST\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "# Hyper-parameters\n",
    "hidden_size = 256\n",
    "drop_prob = 0.8\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDKjNQtfiV7C"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMHR3vi6iV7L"
   },
   "source": [
    "### Non-continual Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18839,
     "status": "ok",
     "timestamp": 1586080107658,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "QV_B2whjiV7N",
    "outputId": "df0fcdab-a7c2-4be6-bf5e-d63f1c8e2ec9"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "train_data = TensorDataset(x_tr, y_tr)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_data = TensorDataset(x_te, y_te)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "model = Classifier(input_size, hidden_size, drop_prob, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for ep in tqdm(range(num_epochs)):\n",
    "    for inputs, labels in train_loader:\n",
    "        if device.type == 'cuda':\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(inputs.float())\n",
    "        loss = criterion(out, labels.long())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "corrects = 0\n",
    "total = 0\n",
    "for inputs, labels in test_loader:\n",
    "    if device.type == 'cuda':\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "    out = model(inputs.float())\n",
    "    preds = torch.argmax(f.softmax(out, dim=-1), dim=-1).cpu().numpy()\n",
    "\n",
    "    tmp_val_loss = criterion(out, labels.long())\n",
    "    val_loss += tmp_val_loss.item()\n",
    "\n",
    "    corrects += sum(preds == labels.cpu().numpy())\n",
    "    total += len(preds)\n",
    "\n",
    "print(\"Loss: {:.6f}, Acc: {:.6f}\".format(val_loss/len(test_loader), (corrects/total)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4EPoQqexyI-"
   },
   "source": [
    "## Skewed Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjbOih6EiV7X"
   },
   "source": [
    "### Continual Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ypbuCNKhwDmF"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# constant validation data across tasks\n",
    "test_data = TensorDataset(x_te, y_te)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7v5XPZx2iV7Z"
   },
   "outputs": [],
   "source": [
    "def test_continual_learner(learner_class, class_probs, use_memory=False):\n",
    "    ''' Tester for continual learners\n",
    "    '''\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "\n",
    "    task_perm_final_accs = []\n",
    "\n",
    "    # continual learning is performed n_tasks(5) times\n",
    "    # for more reliable results\n",
    "    for t in range(n_tasks):\n",
    "        \n",
    "        # initialize models\n",
    "        model = Classifier(input_size, hidden_size, drop_prob, output_size).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        if use_memory:\n",
    "            learner = learner_class(model, criterion, device=device,\n",
    "                                    memory_capacity=memory_capacity, memory_sample_sz=memory_sample_size)\n",
    "        else:\n",
    "            learner = learner_class(model, criterion, device=device)\n",
    "        \n",
    "        # task loop\n",
    "        np.random.shuffle(class_probs)\n",
    "        for T_x, T_y in skewed_split(x_tr, y_tr, class_probs):\n",
    "            train_data = TensorDataset(T_x, T_y)\n",
    "            train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "            learner.prepare(optimizer=torch.optim.Adam, lr=learning_rate)\n",
    "\n",
    "            model.train()\n",
    "            for ep in tqdm(range(num_epochs)):\n",
    "                for inputs, labels in train_loader:\n",
    "                    if device.type == 'cuda':\n",
    "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                    learner.run(inputs, labels)\n",
    "\n",
    "            if use_memory:\n",
    "                # remember a subset\n",
    "                learner.remember(train_data, min_save_sz=task_memory_size)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            corrects = 0\n",
    "            total = 0\n",
    "            for inputs, labels in test_loader:\n",
    "                if device.type == 'cuda':\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                out = model(inputs.float())\n",
    "                preds = torch.argmax(f.softmax(out, dim=-1), dim=-1).cpu().numpy()\n",
    "\n",
    "                tmp_val_loss = criterion(out, labels.long())\n",
    "                val_loss += tmp_val_loss.item()\n",
    "\n",
    "                corrects += sum(preds == labels.cpu().numpy())\n",
    "                total += len(preds)\n",
    "\n",
    "            print(\"Loss: {:.6f}, Acc: {:.6f}\".format(val_loss/len(test_loader), (corrects/total)*100))\n",
    "\n",
    "        task_perm_final_accs.append((corrects/total)*100) # save final accuracy in current task permutation\n",
    "        \n",
    "    print(\"Final Accs: \", task_perm_final_accs, \" Average Final Acc: \", np.array(task_perm_final_accs).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47078,
     "status": "error",
     "timestamp": 1586082297671,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "3Q922JsKxW1z",
    "outputId": "5025c231-011f-451d-b2c6-11a5b893c6cf"
   },
   "outputs": [],
   "source": [
    "# use base class of learners. this trains model\n",
    "# continually without use of the implemented continual learning methods\n",
    "\n",
    "class_probs = gen_prob_dist(dom_prob=0.9)\n",
    "st = time.time()\n",
    "test_continual_learner(Learner, class_probs, use_memory=False)\n",
    "print(\"Elapsed: %.6f s\" % ((time.time() - st)/n_tasks)) # divide to get average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxEJLZfUzZC2"
   },
   "source": [
    "### GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIbbAK6Azasv"
   },
   "outputs": [],
   "source": [
    "memory_capacity = 10240\n",
    "task_memory_size = 2048\n",
    "memory_sample_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 210473,
     "status": "ok",
     "timestamp": 1586083118814,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "3TDisaNkz0pU",
    "outputId": "ea428fe5-6b0d-4ccd-921d-b2f3b1ab9a1a"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "test_continual_learner(GEM, class_probs, use_memory=True)\n",
    "print(\"Elapsed: %.6f s\" % ((time.time() - st)/n_tasks)) # divide to get average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edb8zgJCiV7j"
   },
   "source": [
    "### A-GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79225,
     "status": "ok",
     "timestamp": 1586082672508,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "maYD9isxiV7k",
    "outputId": "fd8ffdea-c007-4d22-d9c6-e00486f4f3e5"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "test_continual_learner(AGEM, class_probs, use_memory=True)\n",
    "print(\"Elapsed: %.6f s\" % ((time.time() - st)/n_tasks)) # divide to get average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMC70yqAiV70"
   },
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1235,
     "status": "ok",
     "timestamp": 1586083655774,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "Ef8GLFB4iV71",
    "outputId": "1b1b8711-7bca-4d73-82eb-294e1807d392"
   },
   "outputs": [],
   "source": [
    "# we halve the memory sampling size the adjust the batch size\n",
    "# so that the number of samples to use for the actual weight update\n",
    "# will still be consistent with the other learning methods\n",
    "memory_sample_size = int(memory_sample_size/2)\n",
    "batch_size = int(batch_size - memory_sample_size)\n",
    "print(memory_sample_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73562,
     "status": "ok",
     "timestamp": 1586083857936,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "08VazkdZiV7-",
    "outputId": "abd88129-d8d9-46c6-fea2-05c4690f1b1a"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "test_continual_learner(ER, class_probs, use_memory=True)\n",
    "print(\"Elapsed: %.6f s\" % ((time.time() - st)/n_tasks)) # divide to get average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1202,
     "status": "ok",
     "timestamp": 1586083871693,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "iQWpx5ih2PrY",
    "outputId": "40f7c754-992f-419b-ab23-c75386da936c"
   },
   "outputs": [],
   "source": [
    "# revert to original values\n",
    "batch_size = int(batch_size + memory_sample_size)\n",
    "memory_sample_size = int(memory_sample_size*2)\n",
    "print(memory_sample_size, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCZCakID9sms"
   },
   "source": [
    "## Class Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DIr5IeGT9vWJ"
   },
   "source": [
    "### Continual Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48209,
     "status": "ok",
     "timestamp": 1586084090398,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "ciDPeQGx9Kjd",
    "outputId": "75850eab-6816-4b1a-fc75-2b14025ea645"
   },
   "outputs": [],
   "source": [
    "class_probs = gen_prob_dist(dom_prob=1.0)\n",
    "st = time.time()\n",
    "test_continual_learner(Learner, class_probs, use_memory=False)\n",
    "print(\"Elapsed: %.6f s\" % ((time.time() - st)/n_tasks)) # divide to get average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKuPQIIJ97a4"
   },
   "source": [
    "### GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 213536,
     "status": "ok",
     "timestamp": 1586084387593,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "W4QHZxs4iV8O",
    "outputId": "01f7cf59-875f-4fc2-e44c-26f76c5face1"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "test_continual_learner(GEM, class_probs, use_memory=True)\n",
    "print(\"Elapsed: %.6f s\" % ((time.time() - st)/n_tasks)) # divide to get average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n19YEtg898a6"
   },
   "source": [
    "### A-GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 78964,
     "status": "ok",
     "timestamp": 1586084497257,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "ZXJLpSLf99Eg",
    "outputId": "184ce345-da07-42ff-efaa-354149852234"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "test_continual_learner(AGEM, class_probs, use_memory=True)\n",
    "print(\"Elapsed: %.6f s\" % ((time.time() - st)/n_tasks)) # divide to get average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hedfXilF99W0"
   },
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1219,
     "status": "ok",
     "timestamp": 1586084527239,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "7CvB_1tH99tJ",
    "outputId": "a59f3004-495c-453c-f8b7-f9a7fa032f82"
   },
   "outputs": [],
   "source": [
    "# we halve the memory sampling size the adjust the batch size\n",
    "# so that the number of samples to use for the actual weight update\n",
    "# will still be consistent with the other learning methods\n",
    "memory_sample_size = int(memory_sample_size/2)\n",
    "batch_size = int(batch_size - memory_sample_size)\n",
    "print(memory_sample_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70847,
     "status": "ok",
     "timestamp": 1586084599145,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "kI0j7PAF-KOC",
    "outputId": "aef40daa-c922-4ca0-83f5-b5b7efa2b9c3"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "test_continual_learner(ER, class_probs, use_memory=True)\n",
    "print(\"Elapsed: %.6f s\" % ((time.time() - st)/n_tasks)) # divide to get average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1586084833429,
     "user": {
      "displayName": "Cj Bayron",
      "photoUrl": "",
      "userId": "16938605288903551329"
     },
     "user_tz": -480
    },
    "id": "45uuWSh2-N_A",
    "outputId": "55ea0ecd-92b0-4f08-e907-19a4a56005f1"
   },
   "outputs": [],
   "source": [
    "# revert to original values\n",
    "batch_size = int(batch_size + memory_sample_size)\n",
    "memory_sample_size = int(memory_sample_size*2)\n",
    "print(memory_sample_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dc1W3R7vBeMW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nIFBcUQNiV6b"
   ],
   "name": "clem.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
