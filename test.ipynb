{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from learners import Learner, GEM, AGEM, ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_tasks = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "import subprocess\n",
    "\n",
    "mnist_path = \"data/mnist.npz\"\n",
    "\n",
    "# URL from: https://github.com/fchollet/keras/blob/master/keras/datasets/mnist.py\n",
    "if not os.path.exists(mnist_path):\n",
    "    subprocess.call(\"wget https://s3.amazonaws.com/img-datasets/mnist.npz\", shell=True)\n",
    "    !mv mnist.npz data/\n",
    "\n",
    "f = np.load('data/mnist.npz')\n",
    "x_tr = torch.from_numpy(f['x_train'])\n",
    "y_tr = torch.from_numpy(f['y_train']).long()\n",
    "x_te = torch.from_numpy(f['x_test'])\n",
    "y_te = torch.from_numpy(f['y_test']).long()\n",
    "f.close()\n",
    "\n",
    "torch.save((x_tr, y_tr), 'data/mnist_train.pt')\n",
    "torch.save((x_te, y_te), 'data/mnist_test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "x_tr, y_tr = torch.load('data/mnist_train.pt') # 60000 samples\n",
    "x_te, y_te = torch.load('data/mnist_test.pt') # 10000 samples\n",
    "\n",
    "# reshape and normalize data\n",
    "x_tr = x_tr.float().view(x_tr.size(0), -1) / 255.0\n",
    "x_te = x_te.float().view(x_te.size(0), -1) / 255.0\n",
    "y_tr = y_tr.view(-1).long()\n",
    "y_te = y_te.view(-1).long()\n",
    "\n",
    "# shuffle datasets\n",
    "p_tr = torch.randperm(x_tr.size(0))\n",
    "p_te = torch.randperm(x_te.size(0))\n",
    "\n",
    "x_tr, y_tr = x_tr[p_tr], y_tr[p_tr]\n",
    "x_te, y_te = x_te[p_te], y_te[p_te]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_task_size = 10000\n",
    "te_task_size = 2000\n",
    "\n",
    "tasks_tr = []\n",
    "tasks_te = []\n",
    "\n",
    "for t in range(n_tasks):\n",
    "    tasks_tr.append([x_tr[t*tr_task_size:(t+1)*tr_task_size], y_tr[t*tr_task_size:(t+1)*tr_task_size]])\n",
    "    tasks_te.append([x_te[t*te_task_size:(t+1)*te_task_size], y_te[t*te_task_size:(t+1)*te_task_size]])\n",
    "\n",
    "torch.save([tasks_tr, tasks_te], 'data/mnist_splitted.pt')\n",
    "torch.save([[x_tr[:(tr_task_size*n_tasks)], y_tr[:(tr_task_size*n_tasks)]],\n",
    "            [x_te[:(te_task_size*n_tasks)], y_te[:(te_task_size*n_tasks)]]], 'data/mnist_all.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewed Split: For simulating training on unbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# probability for each class in each split\n",
    "# each row correspond to a split. each column correspond to a class (0-9)\n",
    "# a cell tells what percentage of data to get from a class, to include in a split\n",
    "class_probs = [\n",
    "    [0.6, 0.6, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.6, 0.6, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.6, 0.6, 0.1, 0.1, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.6, 0.6, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.6, 0.6],\n",
    "]\n",
    "\n",
    "def skewed_split(X, y, class_probs):\n",
    "    '''\n",
    "    '''\n",
    "    count_dict = Counter(y.numpy()) # count_dict[class] = num_of_data_in_class\n",
    "    indices_per_class = [(y==c).nonzero().squeeze() for c in range(len(count_dict))]\n",
    "    # generate random indices TO INDEX THE ACTUAL INDICES for each class\n",
    "    idxs = [torch.randperm(count_dict[i]) for i in range(len(count_dict))]\n",
    "    for prob_set in class_probs:\n",
    "        idxs_to_get = []\n",
    "        for i in range(len(prob_set)):\n",
    "            end_idx = int(prob_set[i]*count_dict[i])\n",
    "            idxs_to_get.append(indices_per_class[i][idxs[i][:end_idx]])\n",
    "            # update indices, we treat the idxs like a stack where we\n",
    "            # remove indices we have already used\n",
    "            idxs[i] = idxs[i][end_idx:]\n",
    "        \n",
    "        idxs_to_get = torch.cat(idxs_to_get)\n",
    "        yield X[idxs_to_get], y[idxs_to_get]\n",
    "\n",
    "\n",
    "# print(Counter(y_te.numpy()))        \n",
    "# for new_x, new_y in skewed_split(x_te, y_te, class_probs):\n",
    "#     print(Counter(new_y.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, drop_prob, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.dropout(self.relu(self.fc1(x)))\n",
    "        logits = self.fc2(out)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "input_size = 784\n",
    "output_size = 10\n",
    "\n",
    "hidden_size = 256\n",
    "drop_prob = 0.8\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-continual Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.129925, Acc: 96.160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "train_data = TensorDataset(x_tr, y_tr)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_data = TensorDataset(x_te, y_te)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "model = Classifier(input_size, hidden_size, drop_prob, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for ep in tqdm(range(num_epochs)):\n",
    "    for inputs, labels in train_loader:\n",
    "        if device.type == 'cuda':\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(inputs.float())\n",
    "        loss = criterion(out, labels.long())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "corrects = 0\n",
    "total = 0\n",
    "for inputs, labels in test_loader:\n",
    "    if device.type == 'cuda':\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "    out = model(inputs.float())\n",
    "    preds = torch.argmax(f.softmax(out, dim=-1), dim=-1).cpu().numpy()\n",
    "\n",
    "    tmp_val_loss = criterion(out, labels.long())\n",
    "    val_loss += tmp_val_loss.item()\n",
    "\n",
    "    corrects += sum(preds == labels.cpu().numpy())\n",
    "    total += len(preds)\n",
    "\n",
    "print(\"Loss: {:.6f}, Acc: {:.6f}\".format(val_loss/len(test_loader), (corrects/total)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continual Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.98it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.870035, Acc: 72.390000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.73it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.689178, Acc: 75.490000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.88it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.538116, Acc: 82.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.65it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.370541, Acc: 89.170000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.97it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.407775, Acc: 88.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.76it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.647544, Acc: 82.090000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.78it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.723041, Acc: 74.550000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.13it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.586379, Acc: 81.410000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.80it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.433023, Acc: 86.390000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.70it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.398603, Acc: 88.270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.05it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.026162, Acc: 62.520000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.87it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.541745, Acc: 83.940000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.80it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.557365, Acc: 82.540000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.78it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.437216, Acc: 87.280000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.85it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.466650, Acc: 84.510000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.83it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.937706, Acc: 65.550000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.67it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.456596, Acc: 86.460000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.80it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.520393, Acc: 84.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.78it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.446332, Acc: 86.510000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.88it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.476800, Acc: 84.710000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.79it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.966641, Acc: 65.320000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.76it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.629363, Acc: 80.830000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.71it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.509547, Acc: 85.270000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.67it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.401000, Acc: 88.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.522265, Acc: 82.730000\n",
      "Final Accs:  [88.6, 88.27000000000001, 84.50999999999999, 84.71, 82.73]  Average Final Acc:  85.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "all_trn_f1_mean = np.array([])\n",
    "all_val_f1_mean = np.array([])\n",
    "\n",
    "task_perm_final_accs = []\n",
    "\n",
    "# constant validation data across tasks\n",
    "test_data = TensorDataset(x_te, y_te)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "class_probs = [\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "]\n",
    "\n",
    "a = 0.9\n",
    "class_probs[0][0], class_probs[0][1] = a, a\n",
    "class_probs[1][2], class_probs[1][3] = a, a\n",
    "class_probs[2][4], class_probs[2][5] = a, a\n",
    "class_probs[3][6], class_probs[3][7] = a, a\n",
    "class_probs[4][8], class_probs[4][9] = a, a\n",
    "\n",
    "for t in range(n_tasks):\n",
    "    \n",
    "    # initialize models\n",
    "    model = Classifier(input_size, hidden_size, drop_prob, output_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learner = Learner(model, criterion, device=device)\n",
    "    \n",
    "    # task loop\n",
    "    np.random.shuffle(class_probs)\n",
    "    for T_x, T_y in skewed_split(x_tr, y_tr, class_probs):\n",
    "        train_data = TensorDataset(T_x, T_y)\n",
    "        train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "        learner.prepare(optimizer=torch.optim.Adam, lr=learning_rate)\n",
    "\n",
    "        model.train()\n",
    "        for ep in tqdm(range(num_epochs)):\n",
    "            for inputs, labels in train_loader:\n",
    "                if device.type == 'cuda':\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                learner.run(inputs, labels)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            if device.type == 'cuda':\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            out = model(inputs.float())\n",
    "            preds = torch.argmax(f.softmax(out, dim=-1), dim=-1).cpu().numpy()\n",
    "\n",
    "            tmp_val_loss = criterion(out, labels.long())\n",
    "            val_loss += tmp_val_loss.item()\n",
    "\n",
    "            corrects += sum(preds == labels.cpu().numpy())\n",
    "            total += len(preds)\n",
    "\n",
    "        print(\"Loss: {:.6f}, Acc: {:.6f}\".format(val_loss/len(test_loader), (corrects/total)*100))\n",
    "\n",
    "    task_perm_final_accs.append((corrects/total)*100) # save final accuracy in current task permutation\n",
    "    \n",
    "print(\"Final Accs: \", task_perm_final_accs, \" Average Final Acc: \", np.array(task_perm_final_accs).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_capacity = 10240\n",
    "task_memory_size = 2048\n",
    "memory_sample_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.81it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.866402, Acc: 72.390000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.35it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.684069, Acc: 76.460000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.536516, Acc: 82.120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.25it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.347333, Acc: 89.980000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.29it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.366177, Acc: 89.570000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.79it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.686351, Acc: 80.190000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.19it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.703333, Acc: 75.260000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.21it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.510532, Acc: 83.310000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.442791, Acc: 85.820000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.359244, Acc: 89.610000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.91it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.047842, Acc: 62.300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.508270, Acc: 85.240000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.27it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.507403, Acc: 84.420000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.11it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.442829, Acc: 86.990000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.18it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.436878, Acc: 85.190000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.19it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.991985, Acc: 63.740000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.26it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.505864, Acc: 84.990000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.31it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.544707, Acc: 83.490000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.15it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.418356, Acc: 87.690000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.17it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.474081, Acc: 84.230000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.77it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.046776, Acc: 61.720000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.00it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.554103, Acc: 82.430000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.450923, Acc: 86.940000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.10s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.385926, Acc: 88.800000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.463445, Acc: 84.170000\n",
      "Final Accs:  [89.57000000000001, 89.61, 85.19, 84.23, 84.17]  Average Final Acc:  86.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "all_trn_f1_mean = np.array([])\n",
    "all_val_f1_mean = np.array([])\n",
    "\n",
    "task_perm_final_accs = []\n",
    "\n",
    "# constant validation data across tasks\n",
    "test_data = TensorDataset(x_te, y_te)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "class_probs = [\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "]\n",
    "\n",
    "a = 0.9\n",
    "class_probs[0][0], class_probs[0][1] = a, a\n",
    "class_probs[1][2], class_probs[1][3] = a, a\n",
    "class_probs[2][4], class_probs[2][5] = a, a\n",
    "class_probs[3][6], class_probs[3][7] = a, a\n",
    "class_probs[4][8], class_probs[4][9] = a, a\n",
    "\n",
    "for t in range(n_tasks):\n",
    "    \n",
    "    # initialize models\n",
    "    model = Classifier(input_size, hidden_size, drop_prob, output_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learner = AGEM(model, criterion, device=device,\n",
    "                   memory_capacity=memory_capacity, memory_sample_sz=memory_sample_size)\n",
    "    \n",
    "    # task loop\n",
    "    np.random.shuffle(class_probs)\n",
    "    for T_x, T_y in skewed_split(x_tr, y_tr, class_probs):\n",
    "        \n",
    "        train_data = TensorDataset(T_x, T_y)\n",
    "        train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "        learner.prepare(optimizer=torch.optim.Adam, lr=learning_rate)\n",
    "\n",
    "        model.train()\n",
    "        for ep in tqdm(range(num_epochs)):\n",
    "            for inputs, labels in train_loader:\n",
    "                if device.type == 'cuda':\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                learner.run(inputs, labels)\n",
    "\n",
    "        # remember a subset\n",
    "        learner.remember(train_data, min_save_sz=task_memory_size)\n",
    "                \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            if device.type == 'cuda':\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            out = model(inputs.float())\n",
    "            preds = torch.argmax(f.softmax(out, dim=-1), dim=-1).cpu().numpy()\n",
    "\n",
    "            tmp_val_loss = criterion(out, labels.long())\n",
    "            val_loss += tmp_val_loss.item()\n",
    "\n",
    "            corrects += sum(preds == labels.cpu().numpy())\n",
    "            total += len(preds)\n",
    "\n",
    "        print(\"Loss: {:.6f}, Acc: {:.6f}\".format(val_loss/len(test_loader), (corrects/total)*100))\n",
    "\n",
    "    task_perm_final_accs.append((corrects/total)*100) # save final accuracy in current task permutation\n",
    "    \n",
    "print(\"Final Accs: \", task_perm_final_accs, \" Average Final Acc: \", np.array(task_perm_final_accs).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_capacity = 10240\n",
    "task_memory_size = 2048\n",
    "memory_sample_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.866402, Acc: 72.390000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.32it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.585152, Acc: 79.640000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.42it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.320832, Acc: 90.290000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.16it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.234624, Acc: 92.890000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.186608, Acc: 94.400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.72it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.702959, Acc: 80.470000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.32it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.645184, Acc: 77.040000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.36it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.430667, Acc: 86.510000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.27it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.280535, Acc: 91.560000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.45it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.190151, Acc: 94.450000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.072220, Acc: 61.240000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.30it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.634849, Acc: 79.110000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.32it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.467497, Acc: 85.600000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.45it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.293324, Acc: 90.950000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.36it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.239104, Acc: 92.240000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.83it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.994789, Acc: 65.180000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.18it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.504372, Acc: 84.120000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.18it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.405203, Acc: 87.360000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.30it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.315597, Acc: 90.660000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.20it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.216350, Acc: 93.240000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.81it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.997628, Acc: 63.310000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.24it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.544294, Acc: 81.980000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.22it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.402807, Acc: 87.980000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.18it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.279255, Acc: 91.770000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.228038, Acc: 92.710000\n",
      "Final Accs:  [94.39999999999999, 94.45, 92.24, 93.24, 92.71000000000001]  Average Final Acc:  93.40799999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "all_trn_f1_mean = np.array([])\n",
    "all_val_f1_mean = np.array([])\n",
    "\n",
    "task_perm_final_accs = []\n",
    "\n",
    "# constant validation data across tasks\n",
    "test_data = TensorDataset(x_te, y_te)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "class_probs = [\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "    [0.025] * 10,\n",
    "]\n",
    "\n",
    "a = 0.9\n",
    "class_probs[0][0], class_probs[0][1] = a, a\n",
    "class_probs[1][2], class_probs[1][3] = a, a\n",
    "class_probs[2][4], class_probs[2][5] = a, a\n",
    "class_probs[3][6], class_probs[3][7] = a, a\n",
    "class_probs[4][8], class_probs[4][9] = a, a\n",
    "\n",
    "for t in range(n_tasks):\n",
    "    \n",
    "    # initialize models\n",
    "    model = Classifier(input_size, hidden_size, drop_prob, output_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learner = ER(model, criterion, device=device,\n",
    "                 memory_capacity=memory_capacity, memory_sample_sz=memory_sample_size)\n",
    "    \n",
    "    # task loop\n",
    "    np.random.shuffle(class_probs)\n",
    "    for T_x, T_y in skewed_split(x_tr, y_tr, class_probs):\n",
    "        \n",
    "        train_data = TensorDataset(T_x, T_y)\n",
    "        train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "        learner.prepare(optimizer=torch.optim.Adam, lr=learning_rate)\n",
    "\n",
    "        model.train()\n",
    "        for ep in tqdm(range(num_epochs)):\n",
    "            for inputs, labels in train_loader:\n",
    "                if device.type == 'cuda':\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                learner.run(inputs, labels)\n",
    "\n",
    "        # remember a subset\n",
    "        learner.remember(train_data, min_save_sz=task_memory_size)\n",
    "                \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            if device.type == 'cuda':\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            out = model(inputs.float())\n",
    "            preds = torch.argmax(f.softmax(out, dim=-1), dim=-1).cpu().numpy()\n",
    "\n",
    "            tmp_val_loss = criterion(out, labels.long())\n",
    "            val_loss += tmp_val_loss.item()\n",
    "\n",
    "            corrects += sum(preds == labels.cpu().numpy())\n",
    "            total += len(preds)\n",
    "\n",
    "        print(\"Loss: {:.6f}, Acc: {:.6f}\".format(val_loss/len(test_loader), (corrects/total)*100))\n",
    "\n",
    "    task_perm_final_accs.append((corrects/total)*100) # save final accuracy in current task permutation\n",
    "    \n",
    "print(\"Final Accs: \", task_perm_final_accs, \" Average Final Acc: \", np.array(task_perm_final_accs).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
